\renewcommand\chaptername{LAMPIRAN}
\chapter{Lampiran Halaman \textit{Login}}
\section{Pemasangan Perangkat Lunak}
\label{lampiranisntalasihalamanlogin}
Berikut adalah perangkat lunak yang dibutuhkan agar halaman \textit{login} dapat digunakan, antara lain:
\begin{enumerate}
	\item \textit{Python} versi 3.5.2.
	\item \textit{Flask} versi 1.0.2.
	\item \textit{Gunicorn} versi 19.8.1.
	\item \textit{Supervisor} versi 3.2.0.
	\item \textit{Nginx} versi 1.10.3.
\end{enumerate}

\subsection{Pemasangan Perangkat Lunak Python}
Berikut adalah langkah-langkah untuk memasang perangkat lunak Python versi 3.5.2 pada \textit{server} yang akan digunakan untuk membangun halaman \textit{login}.\\
\begin{minipage}{\linewidth}
	\begin{lstlisting}[caption=Command untuk installasi Python,language=Python,label=installpython3diserverlogin]
	sudo apt-get update
	sudo apt-get install python3
	\end{lstlisting}
\end{minipage}

\subsection{Pemasangan Perangkat Lunak Flask}
Berikut adalah langkah-langkah untuk memasang perangkat lunak Flask versi 1.0.2 pada \textit{server} yang akan digunakan untuk membangun halaman \textit{login}.\\
\begin{minipage}{\linewidth}
	\begin{lstlisting}[caption=Command untuk installasi Flask,language=Python,label=installflaskdiserverlogin]
	sudo apt-get install python3-pip
	sudo pip install flask
	\end{lstlisting}
\end{minipage}

\subsection{Pemasangan Perangkat Lunak Gunicorn}
Berikut adalah langkah-langkah untuk memasang perangkat lunak Gunicorn versi 19.8.1 pada \textit{server} yang akan digunakan untuk membangun halaman \textit{login}.\\
\begin{minipage}{\linewidth}
 	\begin{lstlisting}[caption=Command untuk installasi Gunicorn,language=Python,label=installgunicorndiserverlogin]
 	sudo pip install gunicorn
 	\end{lstlisting}
\end{minipage}

\subsection{Pemasangan Perangkat Lunak Supervisor}
Berikut adalah langkah-langkah untuk memasang perangkat lunak Supervisor versi 3.2.0 pada \textit{server} yang akan digunakan untuk membangun halaman \textit{login}.\\
\begin{minipage}{\linewidth}
 	\begin{lstlisting}[caption=Command untuk installasi Supervisor,language=Python,label=installsupervisordiserverlogin]
 	sudo apt-get install python-setuptools
 	sudo apt-get install supervisor
 	\end{lstlisting}
\end{minipage}

\subsection{Pemasangan Perangkat Lunak Nginx}
Berikut adalah langkah-langkah untuk memasang perangkat lunak Nginx versi 1.10.3 pada \textit{server} yang akan digunakan untuk membangun halaman \textit{login}.\\
\begin{minipage}{\linewidth}
 	\begin{lstlisting}[caption=Command untuk installasi Nginx,language=Python,label=installnginx]
 	sudo apt-get install nginx
 	\end{lstlisting}
\end{minipage}

\section{Konfigurasi Perangkat Lunak}
Beberapa perangkat lunak pada \textit{server} yang akan digunakan untuk membangun halaman \textit{login} harus dikonfigurasi terlebih dahulu agar dapat digunakan.

\subsection{File Konfigurasi Supervisor}
Berikut adalah file konfigurasi keseluruhan untuk perangkat lunak Supervisor.

  
  \begin{lstlisting}[numbers=left, frame=single,tabsize=2,breaklines,caption={Kode sumber Model Auth},label=modelAuth, language=python]
FQDNLookup true
LoadPlugin syslog

<Plugin syslog>
	LogLevel info
</Plugin>

LoadPlugin cpu
LoadPlugin df
LoadPlugin memory
LoadPlugin network

<Plugin cpu>
	ReportByCpu true
	ReportByState true
	ValuesPercentage true
</Plugin>


<Plugin memory>
	ValuesAbsolute true
	ValuesPercentage true
</Plugin>

<Plugin df>
	Device "/dev/sda6"
	MountPoint "/"
	FSType "ext4"

	IgnoreSelected false

	ReportInodes false

	ValuesAbsolute true
	ValuesPercentage true
</Plugin>

<Plugin network>
	Server "10.151.36.37" "25826"
</Plugin>

<Include "/etc/collectd/collectd.conf.d">
	Filter "*.conf"
</Include>


\end{lstlisting}

\section{File Konfigurasi InfluxDB}
\label{lampiranKonfigurasi InfluxDB}
  Berikut File Konfigurasi Keseluruhan untuk perangkat lunak InfluxDB.
  
  \begin{lstlisting}[numbers=left, frame=single,tabsize=2,breaklines,caption={Kode sumber Model Auth},label=modelAuth, language=python]

reporting-disabled = false

[meta]
  # Where the metadata/raft database is stored
  dir = "/var/lib/influxdb/meta"

  retention-autocreate = true

  # If log messages are printed for the meta service
  logging-enabled = true
  pprof-enabled = false

  # The default duration for leases.
  lease-duration = "1m0s"

[data]
  # Controls if this node holds time series data shards in the cluster
  enabled = true

  dir = "/var/lib/influxdb/data"

  # These are the WAL settings for the storage engine >= 0.9.3
  wal-dir = "/var/lib/influxdb/wal"
  wal-logging-enabled = true
  data-logging-enabled = true

###
### [cluster]
###
### Controls non-Raft cluster behavior, which generally includes how data is
### shared across shards.
###

[cluster]
  shard-writer-timeout = "5s" # The time within which a remote shard must respond to a write request.
  write-timeout = "10s" # The time within which a write request must complete on the cluster.
  max-concurrent-queries = 0 # The maximum number of concurrent queries that can run. 0 to disable.
  query-timeout = "0s" # The time within a query must complete before being killed automatically. 0s to disable.
  max-select-point = 0 # The maximum number of points to scan in a query. 0 to disable.
  max-select-series = 0 # The maximum number of series to select in a query. 0 to disable.
  max-select-buckets = 0 # The maximum number of buckets to select in an aggregate query. 0 to disable.

###
### [retention]
###
### Controls the enforcement of retention policies for evicting old data.
###

[retention]
  enabled = true
  check-interval = "30m"

###
### [shard-precreation]
###
### Controls the precreation of shards, so they are available before data arrives.
### Only shards that, after creation, will have both a start- and end-time in the
### future, will ever be created. Shards are never precreated that would be wholly
### or partially in the past.

[shard-precreation]
  enabled = true
  check-interval = "10m"
  advance-period = "30m"

###
### Controls the system self-monitoring, statistics and diagnostics.
###
### The internal database for monitoring data is created automatically if
### if it does not already exist. The target retention within this database
### is called 'monitor' and is also created with a retention period of 7 days
### and a replication factor of 1, if it does not exist. In all cases the
### this retention policy is configured as the default for the database.

[monitor]
  store-enabled = true # Whether to record statistics internally.
  store-database = "_internal" # The destination database for recorded statistics
  store-interval = "10s" # The interval at which to record statistics

###
### [admin]
###
### Controls the availability of the built-in, web-based admin interface. If HTTPS is
### enabled for the admin interface, HTTPS must also be enabled on the [http] service.
###

[admin]
  enabled = true
  bind-address = ":8083"
  https-enabled = false
  https-certificate = "/etc/ssl/influxdb.pem"

###
### [http]
###
### Controls how the HTTP endpoints are configured. These are the primary
### mechanism for getting data into and out of InfluxDB.
###

[http]
  enabled = true
  bind-address = ":8086"
  auth-enabled = false
  log-enabled = true
  write-tracing = false
  pprof-enabled = false
  https-enabled = false
  https-certificate = "/etc/ssl/influxdb.pem"
  max-row-limit = 10000

###
### [[graphite]]
###
### Controls one or many listeners for Graphite data.
###

[[graphite]]
  enabled = false


###
### [collectd]
###
### Controls one or many listeners for collectd data.
###

[[collectd]]
  enabled = true
   bind-address = ":25826"
   database = "collectd"
   retention-policy = ""
  # These next lines control how batching works. You should have this enabled
  # otherwise you could get dropped metrics or poor performance. Batching
  # will buffer points in memory if you have many coming in.

   batch-size = 5000 # will flush if this many points get buffered
   batch-pending = 10 # number of batches that may be pending in memory
   batch-timeout = "10s" # will flush at least this often even if we haven't hit buffer limit
   read-buffer = 0 # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.
   typesdb = "/usr/share/collectd/types.db"

###
### [opentsdb]
###
### Controls one or many listeners for OpenTSDB data.
###

[[opentsdb]]
  enabled = false
 

###
### [[udp]]
###
### Controls the listeners for InfluxDB line protocol data via UDP.
###

[[udp]]
  enabled = false
 

###
### [continuous_queries]
###
### Controls how continuous queries are run within InfluxDB.
###

[continuous_queries]
  log-enabled = true
  enabled = true
  # run-interval = "1s" # interval for how often continuous queries will be checked if they need to run

\end{lstlisting}

\section{File Inventory Ansible}
\label{lampiranpushnotif}
  Berikut File Inventory dari perangkat lunak Ansible.
  
  \begin{lstlisting}[numbers=left, frame=single,tabsize=2,breaklines,caption={Kode sumber Model Auth},label=modelAuth, language=python]

[worker]
RAHWANA ansible_user=administrator
SRIKANDI ansible_user=administrator
BALADEWA ansible_user=administrator
MEGANANDA ansible_user=administrator

\end{lstlisting}

\chapter{Kode Sumber}
\section{Web Service}
\label{lampiranpushnotif}
  Berikut File Inventory dari perangkat lunak Ansible.
  
  \begin{lstlisting}[numbers=left, frame=single,tabsize=2,breaklines,caption={Kode sumber Model Auth},label=modelAuth, language=python]
var express = require('express');
var mysql = require('mysql');
var Influx = require('influx');
var router = express.Router();
var conn = require('../db-mysql.js');
var Servers=require('../models/Servers');
var math = require('mathjs');
var cmd = require('node-cmd');
var Promise = require('bluebird'); 

var flag = 1;
//apache and nginx
var port = 8080;

var influx = new Influx.InfluxDB({
  host: '10.151.36.37',
  database: 'collectd'
})

function indexOfMax(arr) {
  if (arr.length === 0) {
      return -1;
  }

  var max = arr[0];
  var maxIndex = 0;

  for (var i = 1; i < arr.length; i++) {
      if (arr[i] > max) {
          maxIndex = i;
          max = arr[i];
      }
  }

  return maxIndex;
}


router.get('/', function(req,res){
  var query="SELECT * FROM servers";
  var resources=[];
  var counter=0
  var df=0
  var cpu=0
  conn.query(query, function(err, rows, fields) {
    if(err) {
      return res.json({"Error" : true, err});
    } else {
        servers=rows.length;
        for (var i = 0; i < servers; i++) {
          output= {
            'hostname'   :'',
            'memory' : '',
            'cpu'     : '',
            'df'  : ''
          }
          resources.push(output);          
          Promise.all([
           influx.query(`select last("value") from memory_value where type='percent' and type_instance='free' and time > now() - 24h and host=${Influx.escape.stringLit(rows[i].hostname)} group by host`),
           influx.query(`select mean("value") from cpu_value where type='percent' and type_instance='idle' and time > now() - 24h and host=${Influx.escape.stringLit(rows[i].hostname)} group by host`),
           influx.query(`select last("value") from df_value where type='percent_bytes' and type_instance='free' and time > now() - 24h and host=${Influx.escape.stringLit(rows[i].hostname)} group by host`) 
            ]).spread(function(query1,query2,query3){
              // console.log(query3)
              resources[counter].hostname=query1[0].host
              resources[counter].memory=query1[0].mean
              resources[counter].cpu=query2[0].mean             
              resources[counter].df=query3[0].last
              counter++
              if(counter==servers){
                //AHP
                //Comparison Matrix
                // [     CPU  MEM   DF ]
                // [CPU   1   0.25  0.5]
                // [MEM   4    1     5 ]
                // [DF    2   0.2    1 ]
                var CM = math.matrix([[1, 0.25, 0.5,0,0], [4, 1, 5,0,0], [2, 0.2, 1,0,0]]); 
                //get 3rd root of Comparison Matrix
                CM.subset(math.index(0, 3),math.pow((CM.subset(math.index(0, 0))*CM.subset(math.index(0, 1))*CM.subset(math.index(0, 2))), 1/3));
                CM.subset(math.index(1, 3),math.pow((CM.subset(math.index(1, 0))*CM.subset(math.index(1, 1))*CM.subset(math.index(1, 2))), 1/3));
                CM.subset(math.index(2, 3),math.pow((CM.subset(math.index(2, 0))*CM.subset(math.index(2, 1))*CM.subset(math.index(2, 2))), 1/3));
                //get priority vector of Comparison Matrix
                var sum = CM.subset(math.index(0, 3))+CM.subset(math.index(1, 3))+CM.subset(math.index(2, 3));  
                CM.subset(math.index(0, 4),CM.subset(math.index(0, 3)) / sum)
                CM.subset(math.index(1, 4),CM.subset(math.index(1, 3)) / sum)
                CM.subset(math.index(2, 4),CM.subset(math.index(2, 3)) / sum)                
                
                //getting rate of each server 
                var range = servers + 2;
                var mem = math.ones(servers,range)
                var cpu = math.ones(servers,range)
                var df = math.ones(servers,range)
                for(i=0;i < servers; i++){
                  for (j = 0; j < servers; j++) {
                      mem.subset(math.index(i, j), resources[i].memory/resources[j].memory)
                      cpu.subset(math.index(i, j), resources[i].cpu/resources[j].cpu)
                      df.subset(math.index(i, j), resources[i].df/resources[j].df)
                    }
                }

                var priority = []
                for (var i = 0; i < servers; i++) {
                   priority.push({
                      memory:'',
                      cpu:'',
                      df:''
                   });
                 } 

                //get 3rd root of product(rop) and priority of MEM
                var rop_mem=[];
                var ropmsum=0;
                for(i=0;i < servers; i++){
                  var ropmval=1;
                  for (j = 0; j < servers; j++) {
                      ropmval = ropmval * mem.subset(math.index(i, j))
                      if(j==servers-1){
                        // console.log(ropmval)
                        rop_mem[i]=math.pow(ropmval,1/3);
                        ropmsum = ropmsum + rop_mem[i];
                        }   
                  }
                  if(i==servers-1)
                  var pmval=1;
                  for(k=0;k < rop_mem.length; k++){
                    pmval = rop_mem[k]/ropmsum;
                    priority[k].memory=pmval;
                  }
                }

                //get 3rd root of product(rop) and priority of DF
                var rop_df=[];
                var ropdsum=0;
                for(i=0;i < servers; i++){
                  var ropdval=1;
                  for (j = 0; j < servers; j++) {
                      ropdval = ropdval * df.subset(math.index(i, j))
                      if(j==servers-1){
                        // console.log(ropmval)
                        rop_df[i]=math.pow(ropdval,1/3);
                        ropdsum = ropdsum + rop_df[i];
                        }   
                  }
                  if(i==servers-1)
                  var pdval=1;
                  for(k=0;k < rop_df.length; k++){
                    pdval = rop_df[k]/ropdsum;
                    priority[k].df=pdval;
                  }
                }

                //get 3rd root of product(rop) and priority of CPU
                var rop_cpu=[];
                var ropcsum=0;
                for(i=0;i < servers; i++){
                  var ropcval=1;
                  for (j = 0; j < servers; j++) {
                      ropcval = ropcval * cpu.subset(math.index(i, j))
                      if(j==servers-1){
                        // console.log(ropmval)
                        rop_cpu[i]=math.pow(ropcval,1/3);
                        ropcsum = ropcsum + rop_cpu[i];
                        }   
                  }
                  if(i==servers-1)
                  var pcval=1;
                  for(k=0;k < rop_cpu.length; k++){
                    pcval = rop_cpu[k]/ropcsum;
                    priority[k].cpu=pcval;
                  }
                }
                //getting score => SIgma(priority per criteria * weifgth of node for each criteria) 
                var criteria = 3
                var score=[]               
                for (var i = 0; i < servers; i++) {
                    score[i] = CM.subset(math.index(0, 4))*priority[i].cpu + CM.subset(math.index(1, 4))*priority[i].memory + CM.subset(math.index(2, 4))*priority[i].df             
                }
                var decision = indexOfMax(score);

                command = 'ansible-playbook /home/administrator/TA-Daniel/ansible-test/playbooks/apache.yml --extra-vars "port='+port+' host='+resources[decision].hostname+' name=container'+flag+'"';
                flag ++;
                port ++;
                cmd.get(
                    command,
                    function(err, data, stderr){
                        res.json(data)
                    }
                );
              }
            });
        }
    }
  });
})
module.exports=router;
\end{lstlisting}

\backmatter % Lampiran tanpa judul LAMPIRAN X, biasanya untuk BIODATA PENULIS
	\chapter{BIODATA PENULIS}
		\begin{wrapfigure}{l}{0.3\textwidth}
			\includegraphics[width=0.29\textwidth]{images/cover/pic}
		\end{wrapfigure}
		Fourir Akbar, lahir pada tanggal 25 April 1996 di Surabaya. Penulis merupakan seorang mahasiswa yang sedang menempuh studi di Departemen Informatika Institut Teknologi Sepuluh Nopember. Memiliki beberapa hobi antara lain futsal dan DOTA. Pernah menjadi asisten dosen pada mata kuliah sistem operasi dan mata kuliah jaringan komputer sebanyak dua semester dan pernah menjadi asisten dosen pada mata kuliah sistem terdistribusi sebanyak satu semester. Penulis juga pernah menjadi asisten dosen pendidikan informatika dan komputer terapan (PIKTI) ITS sebanyak empat semester. Selama menempuh pendidikan di kampus, penulis juga aktif dalam organisasi kemahasiswaan, antara lain sebagai Staff Departemen Hubungan Luar Himpunan Mahasiswa Teknik Computer-Informatika pada tahun ke-2. Penulis juga aktif dalam kepanitiaan Schematics, antara lain sebagai Staff Biro Revolutionary Entertainment and Expo with Various Arts pada tahun ke-2 dan menjadi Badan Pengurus Harian (BPH) Biro Perlengkapan dan Transportasi pada tahun ke-3. Penulis juga merupakan salah satu administrator aktif pada Laboratorium Arsitektur dan jaringan Komputer di Departemen Informatika ITS.
\end{document}